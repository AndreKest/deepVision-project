\begin{thebibliography}{15}

% this bibliography is generated by nd24.bst [3.0c2] from 2005-12-21

\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\makeatletter
\newcommand{\dinatlabel}[1]%
{\ifNAT@numbers\else\NAT@biblabelnum{#1}\fi}
\makeatother
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chandra()]{ciouLoss}
\dinatlabel{Chandra } \textsc{Chandra}, Prakash:
\newblock \emph{IoU Loss Functions for Faster and More Accurate Object
  Detection}.
\newblock
  \url{https://learnopencv.com/iou-loss-functions-object-detection/#ciou-complete-iou-loss},
  Abruf: 13. Juli 2023

\bibitem[Contributors()]{yoloArchitecture}
\dinatlabel{Contributors } \textsc{Contributors}, MMYOLO:
\newblock \emph{mmyolo}.
\newblock \url{https://github.com/open-mmlab/mmyolo}, Abruf: 10. Juli 2023

\bibitem[Feng u.\,a.(2021)Feng, Zhong, Gao, Scott, u.
  Huang]{yolov8LabelAssignment}
\dinatlabel{Feng u.\,a. 2021} \textsc{Feng}, Chengjian ; \textsc{Zhong}, Yujie
  ; \textsc{Gao}, Yu ; \textsc{Scott}, Matthew~R.  ; \textsc{Huang}, Weilin:
\newblock TOOD: Task-aligned One-stage Object Detection.
\newblock {In: }\emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}  (2021), S. 3490--3499

\bibitem[Ge u.\,a.(2021)Ge, Liu, Wang, Li, u. Sun]{yoloxPaper}
\dinatlabel{Ge u.\,a. 2021} \textsc{Ge}, Zheng ; \textsc{Liu}, Songtao ;
  \textsc{Wang}, Feng ; \textsc{Li}, Zeming  ; \textsc{Sun}, Jian:
\newblock YOLOX: Exceeding YOLO Series in 2021.
\newblock {In: }\emph{arXiv preprint arXiv:2107.08430}  (2021)

\bibitem[Li u.\,a.(2020)Li, Wang, Wu, Chen, Hu, Li, Tang, u. Yang]{dflLoss}
\dinatlabel{Li u.\,a. 2020} \textsc{Li}, Xiang ; \textsc{Wang}, Wenhai ;
  \textsc{Wu}, Lijun ; \textsc{Chen}, Shuo ; \textsc{Hu}, Xiaolin ;
  \textsc{Li}, Jun ; \textsc{Tang}, Jinhui  ; \textsc{Yang}, Jian:
\newblock Generalized Focal Loss: Learning Qualified and Distributed Bounding
  Boxes for Dense Object Detection.
\newblock {In: }\emph{ArXiv} abs/2006.04388 (2020)

\bibitem[Lin u.\,a.(2016)Lin, Doll{\'a}r, Girshick, He, Hariharan, u.
  Belongie]{yoloxNeckFPN}
\dinatlabel{Lin u.\,a. 2016} \textsc{Lin}, Tsung-Yi ; \textsc{Doll{\'a}r},
  Piotr ; \textsc{Girshick}, Ross~B. ; \textsc{He}, Kaiming ;
  \textsc{Hariharan}, Bharath  ; \textsc{Belongie}, Serge~J.:
\newblock Feature Pyramid Networks for Object Detection.
\newblock {In: }\emph{2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}  (2016), S. 936--944

\bibitem[Liu u.\,a.(2018)Liu, Qi, Qin, Shi, u. Jia]{yoloxNeckPAN}
\dinatlabel{Liu u.\,a. 2018} \textsc{Liu}, Shu ; \textsc{Qi}, Lu ;
  \textsc{Qin}, Haifang ; \textsc{Shi}, Jianping  ; \textsc{Jia}, Jiaya:
\newblock Path Aggregation Network for Instance Segmentation.
\newblock {In: }\emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}  (2018), S. 8759--8768

\bibitem[Megvii-BaseDetection(2021)]{yoloxGitHubRepo}
\dinatlabel{Megvii-BaseDetection 2021} \textsc{Megvii-BaseDetection}:
\newblock \emph{YOLOX}.
\newblock \url{https://github.com/Megvii-BaseDetection/YOLOX}.
\newblock \,Version:\,2021

\bibitem[Mongaras({\natexlab{a}})]{yoloxExplanationHowWorks}
\dinatlabel{Mongaras {\natexlab{a}}} \textsc{Mongaras}, Gabriel:
\newblock \emph{YOLOX Explanation — How Does YOLOX Work?}
\newblock
  \url{https://medium.com/mlearning-ai/yolox-explanation-how-does-yolox-work-3e5c89f2bf78},
  Abruf: 12. Juli 2023

\bibitem[Mongaras({\natexlab{b}})]{yoloxExplanationAug}
\dinatlabel{Mongaras {\natexlab{b}}} \textsc{Mongaras}, Gabriel:
\newblock \emph{YOLOX Explanation — Mosaic and Mixup For Data Augmentation}.
\newblock
  \url{https://medium.com/mlearning-ai/yolox-explanation-mosaic-and-mixup-for-data-augmentation-3839465a3adf},
  Abruf: 12. Juli 2023

\bibitem[Mongaras({\natexlab{c}})]{yoloxExplanationSimOTA}
\dinatlabel{Mongaras {\natexlab{c}}} \textsc{Mongaras}, Gabriel:
\newblock \emph{YOLOX Explanation — SimOTA For Dynamic Label Assignment}.
\newblock
  \url{https://medium.com/mlearning-ai/yolox-explanation-simota-for-dynamic-label-assignment-8fa5ae397f76},
  Abruf: 12. Juli 2023

\bibitem[OpenMMLab()]{yolov8ModelExplanation}
\dinatlabel{OpenMMLab } \textsc{OpenMMLab}:
\newblock \emph{Dive into YOLOv8: How does this state-of-the-art model work?}
\newblock
  \url{https://openmmlab.medium.com/dive-into-yolov8-how-does-this-state-of-the-art-model-work-10f18f74bab1},
  Abruf: 12. Juli 2023

\bibitem[Shah()]{yoloxBackbone}
\dinatlabel{Shah } \textsc{Shah}, Deval:
\newblock \emph{YOLOv4 — Version 3: Proposed Workflow}.
\newblock
  \url{https://medium.com/visionwizard/yolov4-version-3-proposed-workflow-e4fa175b902},
  Abruf: 13. Juli 2023

\bibitem[Tian u.\,a.(2019)Tian, Shen, Chen, u. He]{yoloxAnchorFree}
\dinatlabel{Tian u.\,a. 2019} \textsc{Tian}, Zhi ; \textsc{Shen}, Chunhua ;
  \textsc{Chen}, Hao  ; \textsc{He}, Tong:
\newblock FCOS: Fully Convolutional One-Stage Object Detection.
\newblock {In: }\emph{2019 IEEE/CVF International Conference on Computer Vision
  (ICCV)}  (2019), S. 9626--9635

\bibitem[Zhang()]{datasetSelfDrivingCar}
\dinatlabel{Zhang } \textsc{Zhang}, Edward:
\newblock \emph{Udacity Self Driving Car Dataset}.
\newblock
  \url{https://www.kaggle.com/datasets/sshikamaru/udacity-self-driving-car-dataset},
  Abruf: 23. Juni 2023

\end{thebibliography}
